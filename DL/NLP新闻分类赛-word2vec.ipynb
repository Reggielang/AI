{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T12:37:27.981223Z",
     "start_time": "2025-01-21T12:37:25.276377Z"
    }
   },
   "source": [
    "import logging\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:38:03.734725Z",
     "start_time": "2025-01-21T12:38:03.727823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set seed\n",
    "seed = 789\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# split data to 10 fold\n",
    "fold_num = 10\n",
    "data_file = './data/train_set.csv'\n",
    "\n",
    "def all_data2fold(fold_num, data_file, num=10000):\n",
    "    fold_data = []\n",
    "    df = pd.read_csv(data_file, sep='\\t', encoding='UTF-8')\n",
    "    texts = df['text'].tolist()\n",
    "    labels = df['label'].tolist()\n",
    "\n",
    "    df = df.sample(n=num, random_state=seed)\n",
    "    # Group by label and shuffle within groups\n",
    "    label2data = df.groupby('label')\n",
    "\n",
    "    # Distribute samples evenly across folds while maintaining class balance\n",
    "    fold_texts = [[] for _ in range(fold_num)]\n",
    "    fold_labels = [[] for _ in range(fold_num)]\n",
    "    # print(\"---------flod_data---------\",fold_texts)\n",
    "    for label, group in label2data:\n",
    "        indices = np.array_split(group.index.values, fold_num)\n",
    "        for i, idx in enumerate(indices):\n",
    "            # print(\"---------i, idx---------\",i, idx)\n",
    "            fold_texts[i].extend(df.loc[idx, 'text'].tolist())\n",
    "            fold_labels[i].extend(df.loc[idx, 'label'].tolist())\n",
    "\n",
    "    # Shuffle each fold to ensure randomness\n",
    "    for i in range(fold_num):\n",
    "        combined = list(zip(fold_texts[i], fold_labels[i]))\n",
    "        np.random.shuffle(combined)\n",
    "        fold_texts[i], fold_labels[i] = zip(*combined)\n",
    "\n",
    "        fold_data.append({'label': list(fold_labels[i]), 'text': list(fold_texts[i])})\n",
    "\n",
    "    logging.info(\"Fold lens %s\", str([len(data['label']) for data in fold_data]))\n",
    "\n",
    "    return fold_data"
   ],
   "id": "7b03df8bfa422d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:38:08.922295Z",
     "start_time": "2025-01-21T12:38:05.023259Z"
    }
   },
   "cell_type": "code",
   "source": "fold_data = all_data2fold(10,data_file,200000)",
   "id": "8b5fb9be16252295",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 20:38:08,913 INFO: Fold lens [20007, 20004, 20003, 20002, 20002, 19999, 19998, 19997, 19994, 19994]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:38:14.808043Z",
     "start_time": "2025-01-21T12:38:14.802287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# build train data for word2vec\n",
    "fold_id = 9\n",
    "\n",
    "train_texts = []\n",
    "for i in range(0, fold_id):\n",
    "    data = fold_data[i]\n",
    "    train_texts.extend(data['text'])\n",
    "\n",
    "logging.info('Total %d docs.' % len(train_texts))"
   ],
   "id": "122aaf9cede9d20",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 20:38:14,806 INFO: Total 180006 docs.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:41:03.188567Z",
     "start_time": "2025-01-21T12:38:31.931906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.info('Start training...')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "num_features = 200     # Word vector dimensionality\n",
    "num_workers = 12     # Number of threads to run in parallel\n",
    "\n",
    "train_texts = list(map(lambda x: list(x.split()), train_texts))\n",
    "model = Word2Vec(train_texts, workers=num_workers, vector_size=num_features)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model\n",
    "model.save(\"./word2vec.bin\")"
   ],
   "id": "6b7fce55e0cc4228",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 20:38:31,932 INFO: Start training...\n",
      "2025-01-21 20:38:38,775 INFO: collecting all words and their counts\n",
      "2025-01-21 20:38:38,776 INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2025-01-21 20:38:39,361 INFO: PROGRESS: at sentence #10000, processed 9075944 words, keeping 5306 word types\n",
      "2025-01-21 20:38:39,944 INFO: PROGRESS: at sentence #20000, processed 18143500 words, keeping 5670 word types\n",
      "2025-01-21 20:38:40,538 INFO: PROGRESS: at sentence #30000, processed 27366641 words, keeping 5889 word types\n",
      "2025-01-21 20:38:41,230 INFO: PROGRESS: at sentence #40000, processed 36463643 words, keeping 6025 word types\n",
      "2025-01-21 20:38:41,793 INFO: PROGRESS: at sentence #50000, processed 45426175 words, keeping 6174 word types\n",
      "2025-01-21 20:38:42,356 INFO: PROGRESS: at sentence #60000, processed 54538661 words, keeping 6282 word types\n",
      "2025-01-21 20:38:42,923 INFO: PROGRESS: at sentence #70000, processed 63502525 words, keeping 6340 word types\n",
      "2025-01-21 20:38:43,518 INFO: PROGRESS: at sentence #80000, processed 72667382 words, keeping 6406 word types\n",
      "2025-01-21 20:38:44,113 INFO: PROGRESS: at sentence #90000, processed 81663987 words, keeping 6465 word types\n",
      "2025-01-21 20:38:44,710 INFO: PROGRESS: at sentence #100000, processed 90898769 words, keeping 6508 word types\n",
      "2025-01-21 20:38:45,286 INFO: PROGRESS: at sentence #110000, processed 99872007 words, keeping 6564 word types\n",
      "2025-01-21 20:38:45,893 INFO: PROGRESS: at sentence #120000, processed 109050673 words, keeping 6614 word types\n",
      "2025-01-21 20:38:46,484 INFO: PROGRESS: at sentence #130000, processed 118167866 words, keeping 6656 word types\n",
      "2025-01-21 20:38:47,073 INFO: PROGRESS: at sentence #140000, processed 127207542 words, keeping 6682 word types\n",
      "2025-01-21 20:38:47,657 INFO: PROGRESS: at sentence #150000, processed 136151216 words, keeping 6719 word types\n",
      "2025-01-21 20:38:48,262 INFO: PROGRESS: at sentence #160000, processed 145309507 words, keeping 6767 word types\n",
      "2025-01-21 20:38:48,866 INFO: PROGRESS: at sentence #170000, processed 154480390 words, keeping 6804 word types\n",
      "2025-01-21 20:38:49,454 INFO: PROGRESS: at sentence #180000, processed 163423523 words, keeping 6817 word types\n",
      "2025-01-21 20:38:49,454 INFO: collected 6817 word types from a corpus of 163430332 raw words and 180006 sentences\n",
      "2025-01-21 20:38:49,455 INFO: Creating a fresh vocabulary\n",
      "2025-01-21 20:38:49,463 INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 5971 unique words (87.59% of original 6817, drops 846)', 'datetime': '2025-01-21T20:38:49.463638', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2025-01-21 20:38:49,463 INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 163428661 word corpus (100.00% of original 163430332, drops 1671)', 'datetime': '2025-01-21T20:38:49.463638', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2025-01-21 20:38:49,476 INFO: deleting the raw counts dictionary of 6817 items\n",
      "2025-01-21 20:38:49,477 INFO: sample=0.001 downsamples 62 most-common words\n",
      "2025-01-21 20:38:49,477 INFO: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 141068128.48526365 word corpus (86.3%% of prior 163428661)', 'datetime': '2025-01-21T20:38:49.477638', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'prepare_vocab'}\n",
      "2025-01-21 20:38:49,497 INFO: estimated required memory for 5971 words and 200 dimensions: 12539100 bytes\n",
      "2025-01-21 20:38:49,497 INFO: resetting layer weights\n",
      "2025-01-21 20:38:49,500 INFO: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2025-01-21T20:38:49.500635', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'build_vocab'}\n",
      "2025-01-21 20:38:49,501 INFO: Word2Vec lifecycle event {'msg': 'training model with 12 workers on 5971 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2025-01-21T20:38:49.501634', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "2025-01-21 20:38:50,508 INFO: EPOCH 0 - PROGRESS: at 3.69% examples, 5124893 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:38:51,509 INFO: EPOCH 0 - PROGRESS: at 7.32% examples, 5145387 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:38:52,509 INFO: EPOCH 0 - PROGRESS: at 11.11% examples, 5183443 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:38:53,512 INFO: EPOCH 0 - PROGRESS: at 14.77% examples, 5193832 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:38:54,514 INFO: EPOCH 0 - PROGRESS: at 18.58% examples, 5223847 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:38:55,517 INFO: EPOCH 0 - PROGRESS: at 22.38% examples, 5239175 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:38:56,521 INFO: EPOCH 0 - PROGRESS: at 26.03% examples, 5207422 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:38:57,525 INFO: EPOCH 0 - PROGRESS: at 29.48% examples, 5166908 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:38:58,529 INFO: EPOCH 0 - PROGRESS: at 33.18% examples, 5165843 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:38:59,531 INFO: EPOCH 0 - PROGRESS: at 36.49% examples, 5111920 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:00,532 INFO: EPOCH 0 - PROGRESS: at 40.30% examples, 5124216 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:01,535 INFO: EPOCH 0 - PROGRESS: at 44.09% examples, 5143531 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:02,537 INFO: EPOCH 0 - PROGRESS: at 47.94% examples, 5157218 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:03,538 INFO: EPOCH 0 - PROGRESS: at 51.64% examples, 5158798 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:04,538 INFO: EPOCH 0 - PROGRESS: at 55.34% examples, 5166762 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:05,540 INFO: EPOCH 0 - PROGRESS: at 59.12% examples, 5174380 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:06,542 INFO: EPOCH 0 - PROGRESS: at 63.00% examples, 5185524 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:07,542 INFO: EPOCH 0 - PROGRESS: at 66.75% examples, 5195534 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:08,544 INFO: EPOCH 0 - PROGRESS: at 70.54% examples, 5200212 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:09,545 INFO: EPOCH 0 - PROGRESS: at 74.36% examples, 5207165 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:10,545 INFO: EPOCH 0 - PROGRESS: at 78.20% examples, 5213482 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:11,553 INFO: EPOCH 0 - PROGRESS: at 82.15% examples, 5220593 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:12,558 INFO: EPOCH 0 - PROGRESS: at 85.90% examples, 5225243 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:13,558 INFO: EPOCH 0 - PROGRESS: at 89.68% examples, 5228485 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:14,559 INFO: EPOCH 0 - PROGRESS: at 93.49% examples, 5234182 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:15,561 INFO: EPOCH 0 - PROGRESS: at 97.34% examples, 5239365 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:16,246 INFO: EPOCH 0: training on 163430332 raw words (140190415 effective words) took 26.7s, 5242700 effective words/s\n",
      "2025-01-21 20:39:17,250 INFO: EPOCH 1 - PROGRESS: at 3.75% examples, 5230327 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:18,250 INFO: EPOCH 1 - PROGRESS: at 7.46% examples, 5241566 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:19,253 INFO: EPOCH 1 - PROGRESS: at 11.33% examples, 5280553 words/s, in_qsize 24, out_qsize 2\n",
      "2025-01-21 20:39:20,254 INFO: EPOCH 1 - PROGRESS: at 15.13% examples, 5316297 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:21,257 INFO: EPOCH 1 - PROGRESS: at 18.94% examples, 5332231 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:22,258 INFO: EPOCH 1 - PROGRESS: at 22.81% examples, 5341377 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:23,259 INFO: EPOCH 1 - PROGRESS: at 26.70% examples, 5343865 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:24,264 INFO: EPOCH 1 - PROGRESS: at 30.52% examples, 5349414 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:25,265 INFO: EPOCH 1 - PROGRESS: at 34.35% examples, 5351226 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:26,265 INFO: EPOCH 1 - PROGRESS: at 38.18% examples, 5349854 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:27,265 INFO: EPOCH 1 - PROGRESS: at 42.01% examples, 5346168 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:28,265 INFO: EPOCH 1 - PROGRESS: at 45.79% examples, 5349449 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:29,268 INFO: EPOCH 1 - PROGRESS: at 49.69% examples, 5348253 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:30,268 INFO: EPOCH 1 - PROGRESS: at 53.53% examples, 5350371 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:31,272 INFO: EPOCH 1 - PROGRESS: at 57.28% examples, 5349691 words/s, in_qsize 20, out_qsize 3\n",
      "2025-01-21 20:39:32,275 INFO: EPOCH 1 - PROGRESS: at 61.13% examples, 5348484 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:33,276 INFO: EPOCH 1 - PROGRESS: at 64.94% examples, 5349767 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:34,277 INFO: EPOCH 1 - PROGRESS: at 68.62% examples, 5343351 words/s, in_qsize 24, out_qsize 1\n",
      "2025-01-21 20:39:35,281 INFO: EPOCH 1 - PROGRESS: at 72.45% examples, 5341954 words/s, in_qsize 24, out_qsize 1\n",
      "2025-01-21 20:39:36,283 INFO: EPOCH 1 - PROGRESS: at 76.20% examples, 5338388 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:37,286 INFO: EPOCH 1 - PROGRESS: at 79.98% examples, 5329027 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:38,287 INFO: EPOCH 1 - PROGRESS: at 83.72% examples, 5325549 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:39,287 INFO: EPOCH 1 - PROGRESS: at 87.52% examples, 5326646 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:40,289 INFO: EPOCH 1 - PROGRESS: at 91.26% examples, 5324019 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:41,290 INFO: EPOCH 1 - PROGRESS: at 95.04% examples, 5324277 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:42,291 INFO: EPOCH 1 - PROGRESS: at 98.79% examples, 5320780 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:42,592 INFO: EPOCH 1: training on 163430332 raw words (140194755 effective words) took 26.3s, 5321997 effective words/s\n",
      "2025-01-21 20:39:43,595 INFO: EPOCH 2 - PROGRESS: at 3.61% examples, 5011754 words/s, in_qsize 24, out_qsize 3\n",
      "2025-01-21 20:39:44,598 INFO: EPOCH 2 - PROGRESS: at 6.92% examples, 4848066 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:45,603 INFO: EPOCH 2 - PROGRESS: at 10.56% examples, 4920690 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:46,605 INFO: EPOCH 2 - PROGRESS: at 14.26% examples, 5010980 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:47,606 INFO: EPOCH 2 - PROGRESS: at 17.99% examples, 5052142 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:48,606 INFO: EPOCH 2 - PROGRESS: at 21.70% examples, 5084675 words/s, in_qsize 23, out_qsize 1\n",
      "2025-01-21 20:39:49,610 INFO: EPOCH 2 - PROGRESS: at 25.58% examples, 5118150 words/s, in_qsize 24, out_qsize 2\n",
      "2025-01-21 20:39:50,609 INFO: EPOCH 2 - PROGRESS: at 29.36% examples, 5147682 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:51,615 INFO: EPOCH 2 - PROGRESS: at 33.14% examples, 5160813 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:52,615 INFO: EPOCH 2 - PROGRESS: at 36.96% examples, 5179568 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:53,622 INFO: EPOCH 2 - PROGRESS: at 40.59% examples, 5161264 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:54,624 INFO: EPOCH 2 - PROGRESS: at 44.22% examples, 5159531 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:55,628 INFO: EPOCH 2 - PROGRESS: at 48.01% examples, 5165284 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:39:56,631 INFO: EPOCH 2 - PROGRESS: at 51.80% examples, 5173271 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:57,635 INFO: EPOCH 2 - PROGRESS: at 55.54% examples, 5182563 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:39:58,636 INFO: EPOCH 2 - PROGRESS: at 59.36% examples, 5192877 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:39:59,639 INFO: EPOCH 2 - PROGRESS: at 63.22% examples, 5200437 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:00,639 INFO: EPOCH 2 - PROGRESS: at 66.97% examples, 5209045 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:01,644 INFO: EPOCH 2 - PROGRESS: at 70.75% examples, 5213096 words/s, in_qsize 23, out_qsize 1\n",
      "2025-01-21 20:40:02,648 INFO: EPOCH 2 - PROGRESS: at 74.57% examples, 5218702 words/s, in_qsize 24, out_qsize 2\n",
      "2025-01-21 20:40:03,649 INFO: EPOCH 2 - PROGRESS: at 78.45% examples, 5225132 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:04,656 INFO: EPOCH 2 - PROGRESS: at 82.16% examples, 5218113 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:05,656 INFO: EPOCH 2 - PROGRESS: at 85.70% examples, 5211993 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:06,657 INFO: EPOCH 2 - PROGRESS: at 89.52% examples, 5217786 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:07,658 INFO: EPOCH 2 - PROGRESS: at 93.14% examples, 5212462 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:08,658 INFO: EPOCH 2 - PROGRESS: at 96.52% examples, 5194552 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:09,571 INFO: EPOCH 2: training on 163430332 raw words (140191665 effective words) took 27.0s, 5196828 effective words/s\n",
      "2025-01-21 20:40:10,577 INFO: EPOCH 3 - PROGRESS: at 3.73% examples, 5181772 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:11,581 INFO: EPOCH 3 - PROGRESS: at 7.39% examples, 5180051 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:40:12,587 INFO: EPOCH 3 - PROGRESS: at 11.23% examples, 5220853 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:13,588 INFO: EPOCH 3 - PROGRESS: at 14.81% examples, 5200697 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:14,590 INFO: EPOCH 3 - PROGRESS: at 18.50% examples, 5194766 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:15,591 INFO: EPOCH 3 - PROGRESS: at 22.21% examples, 5196094 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:16,590 INFO: EPOCH 3 - PROGRESS: at 26.08% examples, 5216552 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:17,595 INFO: EPOCH 3 - PROGRESS: at 29.83% examples, 5226424 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:18,596 INFO: EPOCH 3 - PROGRESS: at 33.58% examples, 5228294 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:19,601 INFO: EPOCH 3 - PROGRESS: at 37.33% examples, 5226168 words/s, in_qsize 24, out_qsize 2\n",
      "2025-01-21 20:40:20,602 INFO: EPOCH 3 - PROGRESS: at 41.20% examples, 5237709 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:21,604 INFO: EPOCH 3 - PROGRESS: at 44.91% examples, 5240781 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:22,604 INFO: EPOCH 3 - PROGRESS: at 48.72% examples, 5242176 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:23,605 INFO: EPOCH 3 - PROGRESS: at 52.50% examples, 5243298 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:40:24,606 INFO: EPOCH 3 - PROGRESS: at 56.12% examples, 5239773 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:25,607 INFO: EPOCH 3 - PROGRESS: at 59.85% examples, 5238897 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:26,608 INFO: EPOCH 3 - PROGRESS: at 63.61% examples, 5236861 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:27,613 INFO: EPOCH 3 - PROGRESS: at 67.28% examples, 5236062 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:28,618 INFO: EPOCH 3 - PROGRESS: at 71.06% examples, 5238578 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:29,623 INFO: EPOCH 3 - PROGRESS: at 74.90% examples, 5241571 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:30,624 INFO: EPOCH 3 - PROGRESS: at 78.71% examples, 5243429 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:31,625 INFO: EPOCH 3 - PROGRESS: at 82.49% examples, 5241990 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:32,628 INFO: EPOCH 3 - PROGRESS: at 86.10% examples, 5237580 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:33,629 INFO: EPOCH 3 - PROGRESS: at 89.78% examples, 5233570 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:34,629 INFO: EPOCH 3 - PROGRESS: at 93.52% examples, 5235253 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:35,630 INFO: EPOCH 3 - PROGRESS: at 97.24% examples, 5234047 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:36,381 INFO: EPOCH 3: training on 163430332 raw words (140196479 effective words) took 26.8s, 5229952 effective words/s\n",
      "2025-01-21 20:40:37,384 INFO: EPOCH 4 - PROGRESS: at 3.65% examples, 5082150 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:38,385 INFO: EPOCH 4 - PROGRESS: at 7.34% examples, 5163196 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:39,388 INFO: EPOCH 4 - PROGRESS: at 11.13% examples, 5191098 words/s, in_qsize 24, out_qsize 2\n",
      "2025-01-21 20:40:40,389 INFO: EPOCH 4 - PROGRESS: at 14.84% examples, 5222986 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:41,390 INFO: EPOCH 4 - PROGRESS: at 18.64% examples, 5244218 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:42,390 INFO: EPOCH 4 - PROGRESS: at 22.43% examples, 5255920 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:43,390 INFO: EPOCH 4 - PROGRESS: at 26.16% examples, 5241419 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:44,392 INFO: EPOCH 4 - PROGRESS: at 29.87% examples, 5241689 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:45,392 INFO: EPOCH 4 - PROGRESS: at 33.62% examples, 5244458 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:46,392 INFO: EPOCH 4 - PROGRESS: at 37.41% examples, 5246046 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:47,396 INFO: EPOCH 4 - PROGRESS: at 41.21% examples, 5246349 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:48,396 INFO: EPOCH 4 - PROGRESS: at 44.92% examples, 5250039 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:49,397 INFO: EPOCH 4 - PROGRESS: at 48.73% examples, 5249598 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:50,403 INFO: EPOCH 4 - PROGRESS: at 52.49% examples, 5247420 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:51,403 INFO: EPOCH 4 - PROGRESS: at 56.18% examples, 5250294 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:52,403 INFO: EPOCH 4 - PROGRESS: at 59.90% examples, 5248939 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:53,408 INFO: EPOCH 4 - PROGRESS: at 63.71% examples, 5247171 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:54,409 INFO: EPOCH 4 - PROGRESS: at 67.36% examples, 5246612 words/s, in_qsize 22, out_qsize 1\n",
      "2025-01-21 20:40:55,409 INFO: EPOCH 4 - PROGRESS: at 71.04% examples, 5241221 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:40:56,412 INFO: EPOCH 4 - PROGRESS: at 74.80% examples, 5241142 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:57,415 INFO: EPOCH 4 - PROGRESS: at 78.54% examples, 5237980 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:40:58,416 INFO: EPOCH 4 - PROGRESS: at 82.35% examples, 5237462 words/s, in_qsize 23, out_qsize 1\n",
      "2025-01-21 20:40:59,417 INFO: EPOCH 4 - PROGRESS: at 85.99% examples, 5235149 words/s, in_qsize 21, out_qsize 2\n",
      "2025-01-21 20:41:00,417 INFO: EPOCH 4 - PROGRESS: at 89.67% examples, 5232767 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:41:01,422 INFO: EPOCH 4 - PROGRESS: at 93.38% examples, 5230432 words/s, in_qsize 23, out_qsize 0\n",
      "2025-01-21 20:41:02,422 INFO: EPOCH 4 - PROGRESS: at 97.11% examples, 5231569 words/s, in_qsize 24, out_qsize 0\n",
      "2025-01-21 20:41:03,178 INFO: EPOCH 4: training on 163430332 raw words (140196988 effective words) took 26.8s, 5232284 effective words/s\n",
      "2025-01-21 20:41:03,179 INFO: Word2Vec lifecycle event {'msg': 'training on 817151660 raw words (700970302 effective words) took 133.7s, 5243735 effective words/s', 'datetime': '2025-01-21T20:41:03.179645', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'train'}\n",
      "2025-01-21 20:41:03,179 INFO: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=5971, vector_size=200, alpha=0.025>', 'datetime': '2025-01-21T20:41:03.179645', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'created'}\n",
      "C:\\Users\\kodi\\AppData\\Local\\Temp\\ipykernel_16152\\1794528286.py:9: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "2025-01-21 20:41:03,180 WARNING: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "2025-01-21 20:41:03,181 INFO: Word2Vec lifecycle event {'fname_or_handle': './word2vec.bin', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2025-01-21T20:41:03.181645', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'saving'}\n",
      "2025-01-21 20:41:03,181 INFO: not storing attribute cum_table\n",
      "2025-01-21 20:41:03,186 INFO: saved ./word2vec.bin\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:41:11.279684Z",
     "start_time": "2025-01-21T12:41:10.947376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load model\n",
    "model = Word2Vec.load(\"./word2vec.bin\")\n",
    "\n",
    "# convert format\n",
    "model.wv.save_word2vec_format('./word2vec.txt', binary=False)"
   ],
   "id": "417b31a159ca6ebf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 20:41:10,948 INFO: loading Word2Vec object from ./word2vec.bin\n",
      "2025-01-21 20:41:10,952 INFO: loading wv recursively from ./word2vec.bin.wv.* with mmap=None\n",
      "2025-01-21 20:41:10,953 INFO: setting ignored attribute cum_table to None\n",
      "2025-01-21 20:41:10,973 INFO: Word2Vec lifecycle event {'fname': './word2vec.bin', 'datetime': '2025-01-21T20:41:10.972375', 'gensim': '4.3.3', 'python': '3.12.8 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:48:34) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'loaded'}\n",
      "2025-01-21 20:41:10,975 INFO: storing 5971x200 projection weights into ./word2vec.txt\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T07:26:35.684375Z",
     "start_time": "2025-01-21T07:26:35.680853Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6ab5511fc1191b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "98a5c7a07006e06e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
