{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-06T01:22:22.523042Z",
     "start_time": "2025-03-06T01:22:15.895032Z"
    }
   },
   "source": [
    "import asyncio\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "llm = OllamaLLM(model=\"deepseek-r1:14b\",\n",
    "                verbose=True)\n",
    "\n",
    "# 创建一个提示模板(prompt template)\n",
    "# 这里以对话模型的消息格式为例子，不熟悉openai对话模型消息格式，建议先学习OpenAI的API教程\n",
    "# 下面消息模板，定义两条消息，system消息告诉模型扮演什么角色，user消息代表用户输入的问题，这里用了一个占位符{input} 代表接受一个模版参数input。\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术专家\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 基于LCEL表达式构建LLM链，lcel语法类似linux的pipeline语法，从左到右按顺序执行\n",
    "# 下面编排了一个简单的工作流，首先执行prompt完成提示词模板(prompt template)格式化处理， 然后将格式化后的prompt传递给llm模型执行，最终返回llm执行结果。\n",
    "chain = prompt | llm\n",
    "\n",
    "# 调用LLM链并设置模板参数input,  invoke会把调用参数传递给prompt提示模板，开始chain定义的步骤开始逐步执行。\n",
    "chain.invoke({\"input\": \"帮我写一篇关于AI的技术文章，100个字\"})"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n嗯，用户让我帮忙写一篇关于AI的技术文章，要求是100个字。首先，我需要明确用户的需求是什么。他可能是一个学生或者刚接触AI领域的人，想要一个简洁明了的介绍。\\n\\n接下来，我要考虑内容的方向。AI是个很广泛的领域，100字的话不能太深入，所以得选择最核心的部分。生成式AI最近挺火的，特别是像GPT这样的模型，应该是个不错的选择。\\n\\n然后，我需要确定文章的结构。开头可以点出AI的发展和现状，中间部分介绍生成式AI的能力及其应用领域，最后总结其对社会的影响和未来的潜力。\\n\\n在语言上，要保持简洁明了，避免使用过于专业的术语，让读者容易理解。同时，要突出重点，确保信息准确且有条理。\\n\\n现在，我得控制字数，大约100字左右，所以每句话都要精炼。开头提到AI发展现状，接着介绍生成式AI的特点和应用领域，最后点出其对社会的影响和未来发展潜力。\\n\\n检查一下，这样结构是否合理，内容是否全面，同时确保没有超过字数限制。嗯，应该没问题了。\\n</think>\\n\\n人工智能（Artificial Intelligence, AI）正迅速改变世界。当前，生成式AI技术如GPT系列模型展现出强大的理解和生成能力，能够完成对话、文本创作、图像生成等多种任务。这种技术基于深度学习和大语言模型，在自然语言处理领域取得了突破性进展。其应用已广泛覆盖教育、医疗、金融等多个行业，并将持续推动社会进步与创新。未来，AI将继续深度融合人类生活，带来更多可能性。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T01:22:33.936296Z",
     "start_time": "2025-03-06T01:22:28.283810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 创建一个字符串输出解析器\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 将输出解析器添加到LLM链中，跟前面的例子，区别就是工作流编排，最后一步将llm模型输出的结果传递给output_parser进行格式转换\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 调用LLM链并提出问题\n",
    "result = chain.invoke({\"input\": \"帮我写一篇langchain的技术文章，100个字\"})\n",
    "print(result)"
   ],
   "id": "f402fcd388299390",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "嗯，用户让我帮他写一篇关于LangChain的技术文章，大概100个字。首先，我要弄清楚什么是LangChain。我记得它是一个用于LLM应用的开源框架，可能和链表结构有关？或者是不是跟链式方法有关系？\n",
      "\n",
      "接下来，我需要确定用户的需求是什么。他可能是一位开发者或者是技术专家，想要快速了解LangChain的核心概念、优势以及应用场景。所以，文章应该简洁明了，突出重点。\n",
      "\n",
      "然后，我要考虑结构。开头可以介绍什么是LangChain，接着说明它的主要特点，比如模块化组件和灵活的架构。然后提到它支持哪些功能，比如记忆机制和数据增强。最后，举一个例子或者应用领域，让读者明白它如何帮助开发者构建高效的应用。\n",
      "\n",
      "在写作过程中，要注意用词准确，同时保持语言简洁，控制在100字左右。可能需要多次精简内容，确保信息全面又不冗长。还要检查有没有遗漏的重要点，比如它是否支持多种模型或者集成工具链的能力。\n",
      "</think>\n",
      "\n",
      "LangChain 是一个开源框架，专为构建复杂的语言模型（LLM）应用而设计。其核心思想是将 LLM 与外部数据源、推理逻辑和记忆机制相结合，形成链式处理流程。通过模块化组件和灵活的架构，开发者可以轻松构建高效、可扩展的应用程序，支持对话系统、任务自动化等多种场景。LangChain 的最大优势在于它允许用户自定义链的结构，从而实现高度智能化的任务处理。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. LangChain提示词工程",
   "id": "535913d20bfd42f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T01:41:49.176843Z",
     "start_time": "2025-03-06T01:41:49.172653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "#导入langchain提示词模板库\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    \"你是一个非常有帮助的助手，可以润色内容，使其看起来更简单易读.\"\n",
    "                )\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "        ]\n",
    ")\n",
    "\n",
    "#使用模板参数格式化模板\n",
    "message = chat_template.format_messages(text=\"我不喜欢吃好吃的东西\")\n",
    "print(message)"
   ],
   "id": "1c6dfb1b027b5547",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='你是一个非常有帮助的助手，可以润色内容，使其看起来更简单易读.', additional_kwargs={}, response_metadata={}), HumanMessage(content='我不喜欢吃好吃的东西', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T01:42:45.081116Z",
     "start_time": "2025-03-06T01:42:45.075602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MessagePlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "prompt_template.invoke({\"msgs\": [HumanMessage(content=\"hi!\")]})"
   ],
   "id": "f25da6986a984a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:26:49.295678Z",
     "start_time": "2025-03-06T02:26:48.477659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#提示词追加示例\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"谁的寿命更长，穆罕默德·阿里还是艾伦·图灵？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要跟进问题吗：是的。\n",
    "跟进：穆罕默德·阿里去世时多大？\n",
    "中间答案：穆罕默德·阿里去世时74岁。\n",
    "跟进：艾伦·图灵去世时多大？\n",
    "中间答案：艾伦·图灵去世时41岁。\n",
    "所以最终答案是：穆罕默德·阿里\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"craigslist的创始人是什么时候出生的？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要跟进问题吗：是的。\n",
    "跟进：craigslist的创始人是谁？\n",
    "中间答案：craigslist由Craig Newmark创立。\n",
    "跟进：Craig Newmark是什么时候出生的？\n",
    "中间答案：Craig Newmark于1952年12月6日出生。\n",
    "所以最终答案是：1952年12月6日\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"乔治·华盛顿的祖父母中的母亲是谁？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要跟进问题吗：是的。\n",
    "跟进：乔治·华盛顿的母亲是谁？\n",
    "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
    "跟进：Mary Ball Washington的父亲是谁？\n",
    "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
    "所以最终答案是：Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"《大白鲨》和《皇家赌场》的导演都来自同一个国家吗？\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "这里需要跟进问题吗：是的。\n",
    "跟进：《大白鲨》的导演是谁？\n",
    "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
    "跟进：Steven Spielberg来自哪里？\n",
    "中间答案：美国。\n",
    "跟进：《皇家赌场》的导演是谁？\n",
    "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
    "跟进：Martin Campbell来自哪里？\n",
    "中间答案：新西兰。\n",
    "所以最终答案是：不是\n",
    "\"\"\"\n",
    "  }\n",
    "]"
   ],
   "id": "7db94ac594ef3727",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:26:51.026007Z",
     "start_time": "2025-03-06T02:26:51.021995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#创建小样本示例的格式化程序\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"问题：{question}\\\\n{answer}\")\n",
    "\n",
    "# 提取examples示例集合的一个示例的内容，用于格式化模板内容\n",
    "#examples[0] = {\"name\":'乔治·华盛顿的祖父母中的母亲是谁？','answer':'Joseph ball'}\n",
    "#**examples[0] name='乔治·华盛顿的祖父母中的母亲是谁？', answer='Joseph ball'\n",
    "print(example_prompt.format(**examples[0]))"
   ],
   "id": "fe2f0514c2828037",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：谁的寿命更长，穆罕默德·阿里还是艾伦·图灵？\\n\n",
      "这里需要跟进问题吗：是的。\n",
      "跟进：穆罕默德·阿里去世时多大？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "跟进：艾伦·图灵去世时多大？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:25:25.736725Z",
     "start_time": "2025-03-06T02:25:25.731726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#将示例和格式化程序提供给FewShotPromptTemplate\n",
    "# 接收examples示例数组参数，通过example_prompt提示词模板批量渲染示例内容\n",
    "# suffix和input_variables参数用于在提示词模板最后追加内容， input_variables用于定义suffix中包含的模板参数\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"问题：{input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"乔治·华盛顿的父亲是谁？\"))"
   ],
   "id": "ea7247a04c75a385",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：谁的寿命更长，穆罕默德·阿里还是艾伦·图灵？\\n\n",
      "这里需要跟进问题吗：是的。\n",
      "跟进：穆罕默德·阿里去世时多大？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "跟进：艾伦·图灵去世时多大？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "所以最终答案是：穆罕默德·阿里\n",
      "\n",
      "\n",
      "问题：craigslist的创始人是什么时候出生的？\\n\n",
      "这里需要跟进问题吗：是的。\n",
      "跟进：craigslist的创始人是谁？\n",
      "中间答案：craigslist由Craig Newmark创立。\n",
      "跟进：Craig Newmark是什么时候出生的？\n",
      "中间答案：Craig Newmark于1952年12月6日出生。\n",
      "所以最终答案是：1952年12月6日\n",
      "\n",
      "\n",
      "问题：乔治·华盛顿的祖父母中的母亲是谁？\\n\n",
      "这里需要跟进问题吗：是的。\n",
      "跟进：乔治·华盛顿的母亲是谁？\n",
      "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
      "跟进：Mary Ball Washington的父亲是谁？\n",
      "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
      "所以最终答案是：Joseph Ball\n",
      "\n",
      "\n",
      "问题：《大白鲨》和《皇家赌场》的导演都来自同一个国家吗？\\n\n",
      "这里需要跟进问题吗：是的。\n",
      "跟进：《大白鲨》的导演是谁？\n",
      "中间答案：《大白鲨》的导演是Steven Spielberg。\n",
      "跟进：Steven Spielberg来自哪里？\n",
      "中间答案：美国。\n",
      "跟进：《皇家赌场》的导演是谁？\n",
      "中间答案：《皇家赌场》的导演是Martin Campbell。\n",
      "跟进：Martin Campbell来自哪里？\n",
      "中间答案：新西兰。\n",
      "所以最终答案是：不是\n",
      "\n",
      "\n",
      "问题：乔治·华盛顿的父亲是谁？\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:27:10.706682Z",
     "start_time": "2025-03-06T02:27:01.938121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#大模型有上下文限制，以及token数量限制，所以不可能把所有示例都提供给大模型，需要通过示例选择器选择少量的示例提供给大模型\n",
    "#使用示例选择器\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "# 初始化Ollama嵌入模型\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 这是可供选择的示例列表。\n",
    "    examples,\n",
    "    # 这是用于生成嵌入的嵌入类，该嵌入用于衡量语义相似性。\n",
    "    embeddings,\n",
    "    # 这是用于存储嵌入和执行相似性搜索的VectorStore类。\n",
    "    Chroma,\n",
    "    # 这是要生成的示例数。\n",
    "    k=1\n",
    ")\n",
    "\n",
    "# 选择与输入最相似的示例。\n",
    "question = \"大白鲨的导演是谁？\"\n",
    "selected_examples = example_selector.select_examples({\"question\": question})\n",
    "print(f\"最相似的示例：{question}\")\n",
    "for example in selected_examples:\n",
    "    print(\"\\\\n\")\n",
    "    for k, v in example.items():\n",
    "        print(f\"{k}：{v}\")"
   ],
   "id": "d5b845a4bbfcd43b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kodi\\AppData\\Local\\Temp\\ipykernel_29692\\2464388577.py:7: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:28:53.062957Z",
     "start_time": "2025-03-06T02:28:50.991435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"问题：{input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"乔治·华盛顿的父亲是谁？\"))"
   ],
   "id": "1ee028c7e2a2b293",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "问题：乔治·华盛顿的祖父母中的母亲是谁？\\n\n",
      "这里需要跟进问题吗：是的。\n",
      "跟进：乔治·华盛顿的母亲是谁？\n",
      "中间答案：乔治·华盛顿的母亲是Mary Ball Washington。\n",
      "跟进：Mary Ball Washington的父亲是谁？\n",
      "中间答案：Mary Ball Washington的父亲是Joseph Ball。\n",
      "所以最终答案是：Joseph Ball\n",
      "\n",
      "\n",
      "问题：乔治·华盛顿的父亲是谁？\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. LangChain工作流编排",
   "id": "29ee32a71dd01603"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:41:32.287839Z",
     "start_time": "2025-03-06T02:41:30.891663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "model = OllamaLLM(model=\"deepseek-r1:14b\",\n",
    "                verbose=True)\n",
    "\n",
    "chunks=[]\n",
    "for chunk in model.stream(\"你好，我是langchain\"):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk,end=\"|\",flush=True)"
   ],
   "id": "3a6502902d5a909f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "\n",
      "|</think>|\n",
      "\n",
      "|你好|！|我是|由|中国的|深度|求|索|（|Deep|Seek|）|公司|独立|开发|的|智能|助手|Deep|Seek|-R|1|-L|ite|-|Preview|，|很高兴|为您提供|服务|！||"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:58:46.115738Z",
     "start_time": "2025-03-06T02:58:40.607699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#chain(链） LCEL通过将LangChain对象连接在一起，形成工作流,使用LCEL创建的链，可以自动实现stream和astream方法,从而实现对最终输出的流式传输。\n",
    "#astream_chain.py\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"给我讲一个关于{topic}的笑话\")\n",
    "parser = StrOutputParser()\n",
    "chain = prompt | model | parser\n",
    "\n",
    "async for chunk in chain.astream({\"topic\": \"鹦鹉\"}):\n",
    "    print(chunk, end=\"|\", flush=True)"
   ],
   "id": "be7776cac3e2027d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "|好吧|，|我现在|要|给|用户|讲|一个|关于|鹦|鹉|的|笑话|。|首先|，|我|需要|回想|一下|有哪些|常见的|鹦|鹉|笑话|主题|，|通常|这些|笑话|都|涉及到|鹦|鹉|模仿|说话|的能力|或者|它们|的|聪明|程度|。\n",
      "\n",
      "|然后|，|我想|到了|一个|经典的|结构|：“|为什么|鹦|鹉|？”| 这|种|结构|通常|用来|引|出|双|关|语|或|谐|音|笑|点|。|比如|，|使用|“|啤酒|”|和|“|皮|”的|发音|相似|，|可能会|制造|笑|点|。\n",
      "\n",
      "|接下来|，|我|需要|考虑|如何|让|笑话|自然|流畅|。|例如|，|设置|一个|场景|：|一个人|在|买|鹦|鹉|，|然后|问|鹦|鹉|是否会|说|某些|话|。|鹦|鹉|的回答|带|有一个|双|关|语|，|比如|提到|啤酒|和|皮|，|这样|能|引发|笑声|。\n",
      "\n",
      "|最后|，|确保|笑话|简|短|有趣|，|容易|理解|，|同时|结尾|有一个|出|人|意|料|的|笑|点|，|让|听众|会|心|一笑|。\n",
      "|</think>|\n",
      "\n",
      "|为什么|鹦|鹉|总|喜欢|谈论|啤酒|？\n",
      "\n",
      "|因为|它们|想|“|皮|”|一下|！|😄||"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:08:10.094513Z",
     "start_time": "2025-03-06T03:07:53.113654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "#流式输出json\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = (\n",
    "        model | JsonOutputParser()\n",
    "    # 由于Langchain旧版本中的一个错误，JsonOutputParser未能从某些模型中流式传输结果\n",
    ")\n",
    "# async def async_stream():\n",
    "#     async for text in chain.astream(\n",
    "#             \"以JSON 格式输出法国、西班牙和日本的国家及其人口列表。\"\n",
    "#             '使用一个带有“countries”外部键的字典，其中包含国家列表。'\n",
    "#             \"每个国家都应该有键`name`和`population`\"\n",
    "#     ):\n",
    "#         print(text, flush=True)\n",
    "\n",
    "async for text in chain.astream(\n",
    "        \"以JSON 格式输出法国、西班牙和日本的国家及其人口列表。\"\n",
    "        '使用一个带有“countries”外部键的字典，其中包含国家列表。'\n",
    "        \"每个国家都应该有键`name`和`population`\"):\n",
    "        print(text, flush=True)"
   ],
   "id": "7d54be58a4820a7d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{'countries': []}\n",
      "{'countries': [{}]}\n",
      "{'countries': [{'name': ''}]}\n",
      "{'countries': [{'name': '法国'}]}\n",
      "{'countries': [{'name': '法国', 'population': 6}]}\n",
      "{'countries': [{'name': '法国', 'population': 67}]}\n",
      "{'countries': [{'name': '法国', 'population': 670}]}\n",
      "{'countries': [{'name': '法国', 'population': 6700}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000}]}\n",
      "{'countries': [{'name': '法国', 'population': 670000}]}\n",
      "{'countries': [{'name': '法国', 'population': 6700000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': ''}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙'}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 4}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 470}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 4700}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 470000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 4700000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': ''}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本'}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 1}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 12}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 125}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 1250}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 12500}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 125000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 1250000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 12500000}]}\n",
      "{'countries': [{'name': '法国', 'population': 67000000}, {'name': '西班牙', 'population': 47000000}, {'name': '日本', 'population': 125000000}]}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:08:10.102048Z",
     "start_time": "2025-03-06T03:08:10.100025Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ee4f190716c76401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T02:26:14.771387Z",
     "start_time": "2025-03-06T02:26:14.769534Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ebd111cb37530a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:27:52.570237Z",
     "start_time": "2025-03-06T03:27:52.568015Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2c2e2e3e060a0baf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:27:52.937216Z",
     "start_time": "2025-03-06T03:27:52.935286Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "321186b0f7acbb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:27:53.104036Z",
     "start_time": "2025-03-06T03:27:53.102033Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2964b79123c95497",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:27:53.269111Z",
     "start_time": "2025-03-06T03:27:53.267228Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "487426e4d84c1e8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:27:53.433532Z",
     "start_time": "2025-03-06T03:27:53.431329Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "be39bff524e80c78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-06T03:27:53.592271Z",
     "start_time": "2025-03-06T03:27:53.590606Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "79aaf18a2c619390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea040ddba08c7276"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
